{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(639, 21) (639,)\n",
      "(345, 21) (345,)\n",
      "[ 0.82120827  0.82725783  0.78887957  0.76148889  0.70578128  0.69610133\n",
      "  0.71928815  0.66876428  0.81526685  0.68774101  0.77938956  0.6909536\n",
      "  0.63713775  0.72724186  0.80355532  0.71025982  0.76066489  0.49376128\n",
      "  0.77248025  0.74897098  1.08050048  0.71025982  0.66003065  0.64138145\n",
      "  0.95464411  0.72724186  0.76148889  0.74987983  0.73797018  0.84031091\n",
      "  0.32524816  0.73797018  0.76904156  0.68843497  0.71313148  0.64138145\n",
      "  0.61750748  0.22433781  0.69063074  0.59786243  0.70578128  0.64138145\n",
      "  0.74203865  0.81007347  0.66003065  0.66957047  0.45358122  0.64045134\n",
      "  0.74286226  0.66003065  0.8093091   0.68018835  0.16516998  0.73009745\n",
      "  0.76974901  0.95464411  0.73083791  0.76904156  0.70708417  0.66003065\n",
      "  1.03413778  0.69628454  0.05469839  0.78054515  0.76323993  0.76007608\n",
      "  0.71114182  0.71025982  0.77767813  0.76755725  0.23527795  0.86366368\n",
      "  0.66909182  1.0118011   0.80279017  0.81661017  0.73076299  0.6632063\n",
      "  0.25654044  0.64138145  0.69498514  0.68018835  0.67626618  0.7164722\n",
      "  0.8494735   0.77511335  0.85427883  0.66003065  0.9275024   0.92900141\n",
      "  0.75231955  0.60024354  0.73479453  0.70708417  0.68018835  0.70708417\n",
      "  0.66003065  1.02940799  0.49376128  0.74456461  0.68774101  0.72226325\n",
      "  0.72997051  0.70708417  0.66003065  0.72226325  0.64138145  0.72724186\n",
      "  0.70431269  0.85381022  0.70708417  0.6632063   0.30559427  0.75768087\n",
      "  0.66003065  0.77097672  0.73797018  0.59292682  0.9305792   0.66003065\n",
      "  0.71614533  0.70832891  0.50138455 -0.05435512  0.70708417  0.70028115\n",
      "  0.789508    0.44003101  0.64138145  0.49376128  0.75099561  0.66003065\n",
      "  0.58863159  0.70578128  0.73479453  0.14044303  0.79273917  0.6632063\n",
      "  0.66003065  0.74203865  0.78887957  0.66003065  0.74203865  0.70839871\n",
      "  0.73611948  0.06943172  0.66909182  0.74851055  0.80233839  0.78071288\n",
      "  0.80457395  0.83603312  0.79213171  0.50063474  0.64138145  0.73542171\n",
      "  0.69030699  1.01566261  0.69705023  0.62445437  0.64138145  1.03413778\n",
      "  0.72050374  0.71313148  0.69381056  0.59998768  0.68018835  0.66003065\n",
      "  0.64138145  0.52681212  0.72724186  0.5948066   0.18478996  0.6632063\n",
      "  0.8600857   0.70981282  0.74004936  0.62907168  0.79804912  0.64138145\n",
      "  0.66003065  0.66003065  0.72198804  0.6632063   1.06012617  0.76904156\n",
      "  0.63048431  0.52147165 -0.08537325  0.66003065  0.81183929  0.68018835\n",
      "  0.49867226  0.71614533  0.66003065  0.73041751  0.74453451  0.78116066\n",
      "  0.15591167  0.23590943  0.68018835  0.68018835  0.87406076  0.85381022\n",
      "  0.68843497  0.70708417  0.78875573  0.92982309  0.73412899  0.64138145\n",
      "  0.83706962  0.68018835  0.78396752  0.89728193  0.75625716  0.17117175\n",
      "  0.79683904  0.74334697  0.6632063   0.52147165  0.68018835  0.6632063\n",
      "  0.98894719  0.85369569  0.68817122  0.64661046  0.70708417  0.66003065\n",
      "  0.15955644  0.75231955  0.74266679  0.63414886  0.57954268  0.64138145\n",
      "  0.66003065  0.74595218  0.71025982  0.13648249  0.66607796  0.74997361\n",
      "  0.80457395  0.815066    0.69498514  0.64138145  0.64793604  0.82676959\n",
      "  0.77358617  0.66003065  0.68266883  0.75495222  0.23665291 -0.25462703\n",
      "  0.52257583  0.72724186  0.36818542  0.86957721  0.68549812  0.72542674\n",
      "  0.88172581  0.67702949  0.78105556  0.77371393  0.78004005  0.71614533\n",
      "  0.78436981  0.69091666  0.79527105  0.63414886  0.68817122  0.70578128\n",
      "  0.75768087  0.64138145  0.72331969  0.68774101  0.2222568   0.64138145\n",
      "  0.66003065  0.72724186  0.9275024   0.66003065  0.59592279  0.68266883\n",
      "  0.53538588  0.72799151  0.75520033  0.74393641  0.64138145  0.73933648\n",
      "  0.69427768  0.72331969  0.63722243  0.82923779  0.73479453  0.02120676\n",
      "  0.76974901  0.73479453  0.86932982  0.73479453  0.72038347  0.66003065\n",
      "  0.77439805  0.94804292  0.64138145  0.65449981  0.66003065  0.64138145\n",
      "  0.6632063   1.03413778  0.83587778  0.66003065  0.69429873  0.8504639\n",
      "  0.86878944  0.72226325  1.07715191  0.7164722   0.84432053  0.76031656\n",
      "  0.69427768  0.72911479  0.90531187  0.02040875  0.78947446  0.85651121\n",
      "  0.70708417  0.83877198  0.76904156  0.64138145  0.75455193  0.70708417\n",
      "  0.66003065  0.71313148  0.75120336  0.72724186  0.64138145  0.70578128\n",
      "  0.70789871  0.6632063   0.85346937  0.92837829  0.46670325  0.72468699\n",
      "  0.46655387  1.03593694  0.98894719]\n",
      "Train/Test split results:\n",
      " accuracy on train set is 0.856\n",
      "Logistic Regression Score 0.739\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import accuracy_score \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "interviews_LR = pd.read_csv('D:\\Spring 18\\ML\\Project\\CleanedInterviews - 04.14.18.csv')\n",
    "\n",
    "\n",
    "interviews_LR = interviews_LR.dropna()\n",
    "\n",
    "interviews_LR = interviews_LR.apply(LabelEncoder().fit_transform)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Y_train=interviews_LR['Observed Attendance']\n",
    "del interviews_LR['Observed Attendance']\n",
    "\n",
    "X_train = interviews_LR\n",
    "interviews_LR.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.35, random_state=42)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "############################################################\n",
    "\n",
    "#Random Forest implementation\n",
    "\n",
    "############################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "randomf.fit(X_train,y_train)\n",
    "score = randomf.score(X_test, y_test)\n",
    "prediction_randomForest = randomf.predict(X_test)\n",
    "prediction_randomForest_train=randomf.predict(X_train)\n",
    "print('Train/Test split results:')\n",
    "print(\" Random Forest score is %2.3f\" % accuracy_score(y_train, prediction_randomForest_train))\n",
    "\n",
    "############################################################\n",
    "\n",
    "# Logistic Regression implementation\n",
    "\n",
    "############################################################\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)\n",
    "print(predictions)\n",
    "log=LogisticRegression()\n",
    "result  = log.fit(X_train,y_train)\n",
    "score = log.score(X_test, y_test)\n",
    "print(\"Logistic Regression Score %2.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
